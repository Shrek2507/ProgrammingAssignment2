{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Book_Reviews_Analysis(object):\n",
    "    def __init__(self):\n",
    "        self.bookReviews = None\n",
    "        self.stopWords = None\n",
    "        self.vectorizer = None\n",
    "        self.model = None\n",
    "        self.features = None\n",
    "        self.labels = None\n",
    "        self.features_train = None\n",
    "        self.labels_train = None\n",
    "        self.features_test = None\n",
    "        self.labels_test = None\n",
    "    \n",
    "    # function to fetch the data....\n",
    "    def extractData(self, url):\n",
    "        try:\n",
    "            print(\"Extracting data from url....\")\n",
    "            self.bookReviews = pd.read_csv(url, sep=\"\\t\", names=['Review', 'text'])\n",
    "            \n",
    "            print(\"Data extracted from url : \")\n",
    "            \n",
    "            return self.bookReviews\n",
    "        except Exception as e:\n",
    "            print(\"Exception Caught is : \", e)\n",
    "        \n",
    "    # function to create stopwords...\n",
    "    def createStopWords(self):\n",
    "        self.stopWords = set(stopwords.words('english'))\n",
    "        print \"Stopwords are : \"\n",
    "        \n",
    "        return self.stopWords\n",
    "    \n",
    "    # function to pre-process our data...\n",
    "    def preProcessData(self, data, vectorizer_type):\n",
    "        transformedData = None\n",
    "        if vectorizer_type == \"TfIdf\":\n",
    "            print(\"Creating a Tf-Idf vectorizer for the given data...\")\n",
    "            self.vectorizer = self.createTFIDFVectorization()\n",
    "            \n",
    "            # transform the data....\n",
    "            transformedData = self.vectorizer.fit_transform(data['text'])\n",
    "            print(\"Data type is : \", type(transformedData))\n",
    "            self.labels = data[\"Review\"]\n",
    "            \n",
    "        elif vectorizer_type == \"CV\":\n",
    "            print(\"Creating the count vectorizer for the given data...\")\n",
    "        \n",
    "        return transformedData, self.labels\n",
    "    \n",
    "            \n",
    "    # function to perform tf-idf vectorization...\n",
    "    def createTFIDFVectorization(self):\n",
    "        # instantiating a Tf-Idf vectorizer...\n",
    "        self.vectorizer = TfidfVectorizer(use_idf=True, lowercase=True, strip_accents='ascii', stop_words=self.stopWords)\n",
    "        \n",
    "        return self.vectorizer\n",
    "    \n",
    "    # method to split the data....\n",
    "    def split_the_data(self, transformedData):\n",
    "        print(\"Splitting the data into train and test....\")\n",
    "        self.features = transformedData\n",
    "        self.features_train, self.features_test, self.labels_train, self.labels_test = train_test_split(self.features, self.labels, random_state=42)\n",
    "        \n",
    "        print(\"Data split is completed....\")\n",
    "        \n",
    "        return self.features_train, self.features_test, self.labels_train, self.labels_test\n",
    "    \n",
    "    # create a classifier....\n",
    "    def createClassifier(self, classifier_type):\n",
    "        if classifier_type == 'MNB':\n",
    "            print(\"Creating a Multinomial Classifier....\")\n",
    "            self.model = MultinomialNB()\n",
    "            \n",
    "            return self.model\n",
    "            \n",
    "        elif classifier_type == \"LR\":\n",
    "            print(\"Creating a Logistic Regression Classifier....\")\n",
    "            self.model = LogisticRegression()\n",
    "            \n",
    "            return self.model\n",
    "            \n",
    "    # train the data...\n",
    "    def trainData(self, classifier_type, features, labels, data_type):\n",
    "        try:\n",
    "            # create a classifier...\n",
    "            self.model = self.createClassifier(classifier_type)\n",
    "            if data_type == 'train':\n",
    "                print(\"Training the model on trained data...\")\n",
    "                start_time = time()\n",
    "                \n",
    "                # train the data....\n",
    "                self.model.fit(features, labels)\n",
    "        \n",
    "                end_time = time()\n",
    "    \n",
    "                training_time = end_time - start_time\n",
    "                print(\"Training data is trained on the \"+classifier_type+\" classifier. \"+\" The training time is : \"+str(float(training_time)))\n",
    "            \n",
    "            elif data_type == 'test':\n",
    "                # work on test data...\n",
    "                print(\"Training the moel on test data....\")\n",
    "                start_time = time()\n",
    "                \n",
    "                # train the data...\n",
    "                self.model.fit(features, labels)\n",
    "                \n",
    "                end_time = time()\n",
    "                \n",
    "                training_time = end_time - start_time\n",
    "                print(\"Testing data is trained on the \"+classifier_type+\" classifier. \"+\" The training time is : \"+str(float(training_time)))\n",
    "            \n",
    "            return self.model, training_time\n",
    "        \n",
    "        except Exception as ex:\n",
    "            print(\"Exception Caught is : \", ex)\n",
    "        \n",
    "        \n",
    "    # make predictions...\n",
    "    def predictResult(self, classifier, feature):\n",
    "        # predict the result....\n",
    "        labels_pred = classifier.predict(feature)\n",
    "        \n",
    "        return labels_pred\n",
    "    \n",
    "    def checkForAccuracy(self, labels_pred, labels_true):\n",
    "        # generate classification report...\n",
    "        return classification_report(labels_pred, labels_true)\n",
    "        \n",
    "    def validateForNewVector(self, movie_array):\n",
    "        movie_review_vector = self.vectorizer.transform(movie_array)\n",
    "        sts_movie_review = \"\"\n",
    "        result = int(self.model.predict(movie_review_vector))\n",
    "        \n",
    "        if result == 0:\n",
    "            sts_movie_review = \"Negative\"\n",
    "        elif result == 1:\n",
    "            sts_movie_review = \"Positive\"\n",
    "            \n",
    "        return sts_movie_review\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating object...\n",
      "Object Created\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating object...\")\n",
    "br = Book_Reviews_Analysis()\n",
    "print(\"Object Created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data from url....\n",
      "Data extracted from url : \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The Da Vinci Code book is just awesome.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>this was the first clive cussler i've ever rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>i liked the Da Vinci Code a lot.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>i liked the Da Vinci Code a lot.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>I liked the Da Vinci Code but it ultimatly did...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Review                                               text\n",
       "0       1            The Da Vinci Code book is just awesome.\n",
       "1       1  this was the first clive cussler i've ever rea...\n",
       "2       1                   i liked the Da Vinci Code a lot.\n",
       "3       1                   i liked the Da Vinci Code a lot.\n",
       "4       1  I liked the Da Vinci Code but it ultimatly did..."
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://raw.githubusercontent.com/mbernico/CS570/master/data/UMICH_SI650_Sentiment_Classification.txt\"\n",
    "bookReviews = br.extractData(url)\n",
    "bookReviews.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopwords are : \n",
      "set([u'all', u'just', u\"don't\", u'being', u'over', u'both', u'through', u'yourselves', u'its', u'before', u'o', u'don', u'hadn', u'herself', u'll', u'had', u'should', u'to', u'only', u'won', u'under', u'ours', u'has', u\"should've\", u\"haven't\", u'do', u'them', u'his', u'very', u\"you've\", u'they', u'not', u'during', u'now', u'him', u'nor', u\"wasn't\", u'd', u'did', u'didn', u'this', u'she', u'each', u'further', u\"won't\", u'where', u\"mustn't\", u\"isn't\", u'few', u'because', u\"you'd\", u'doing', u'some', u'hasn', u\"hasn't\", u'are', u'our', u'ourselves', u'out', u'what', u'for', u\"needn't\", u'below', u're', u'does', u\"shouldn't\", u'above', u'between', u'mustn', u't', u'be', u'we', u'who', u\"mightn't\", u\"doesn't\", u'were', u'here', u'shouldn', u'hers', u\"aren't\", u'by', u'on', u'about', u'couldn', u'of', u\"wouldn't\", u'against', u's', u'isn', u'or', u'own', u'into', u'yourself', u'down', u\"hadn't\", u'mightn', u\"couldn't\", u'wasn', u'your', u\"you're\", u'from', u'her', u'their', u'aren', u\"it's\", u'there', u'been', u'whom', u'too', u'wouldn', u'themselves', u'weren', u'was', u'until', u'more', u'himself', u'that', u\"didn't\", u'but', u\"that'll\", u'with', u'than', u'those', u'he', u'me', u'myself', u'ma', u\"weren't\", u'these', u'up', u'will', u'while', u'ain', u'can', u'theirs', u'my', u'and', u've', u'then', u'is', u'am', u'it', u'doesn', u'an', u'as', u'itself', u'at', u'have', u'in', u'any', u'if', u'again', u'no', u'when', u'same', u'how', u'other', u'which', u'you', u\"shan't\", u'shan', u'needn', u'haven', u'after', u'most', u'such', u'why', u'a', u'off', u'i', u'm', u'yours', u\"you'll\", u'so', u'y', u\"she's\", u'the', u'having', u'once'])\n"
     ]
    }
   ],
   "source": [
    "# create a lit of stopwords....\n",
    "stopWords = br.createStopWords()\n",
    "print(stopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a Tf-Idf vectorizer for the given data...\n",
      "('Data type is : ', <class 'scipy.sparse.csr.csr_matrix'>)\n",
      "('Shape of the feature data is : ', (6918, 2011))\n",
      "('Shape of labels is : ', (6918L,))\n"
     ]
    }
   ],
   "source": [
    "transformedData, target = br.preProcessData(bookReviews, \"TfIdf\")\n",
    "print(\"Shape of the feature data is : \", transformedData.shape)\n",
    "\n",
    "print(\"Shape of labels is : \", target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting the data into train and test....\n",
      "Data split is completed....\n",
      "('Shape of train features are : ', (5188, 2011))\n",
      "('Shape of the train labels are : ', (5188L,))\n"
     ]
    }
   ],
   "source": [
    "# split the data....\n",
    "features_train, features_test, labels_train, labels_test = br.split_the_data(transformedData)\n",
    "\n",
    "print(\"Shape of train features are : \", features_train.shape)\n",
    "print(\"Shape of the train labels are : \", labels_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a Multinomial Classifier....\n",
      "Training the model on trained data...\n",
      "Training data is trained on the MNB classifier.  The training time is : 0.00600004196167\n"
     ]
    }
   ],
   "source": [
    "# train the training data...\n",
    "classifier, training_time = br.trainData(\"MNB\", features_train, labels_train, \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for the training data is : \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99      2218\n",
      "          1       1.00      0.99      0.99      2970\n",
      "\n",
      "avg / total       0.99      0.99      0.99      5188\n",
      "\n",
      "('Accuracy score for training data is : ', 99.402467232074017)\n"
     ]
    }
   ],
   "source": [
    "# check for accuracy...\n",
    "labels_pred_train = br.predictResult(classifier, features_train)\n",
    "\n",
    "print(\"Classification report for the training data is : \")\n",
    "print br.checkForAccuracy(labels_pred_train, labels_train)\n",
    "\n",
    "print(\"Accuracy score for training data is : \", accuracy_score(labels_pred_train, labels_train)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a Multinomial Classifier....\n",
      "Training the moel on test data....\n",
      "Testing data is trained on the MNB classifier.  The training time is : 0.00300002098083\n"
     ]
    }
   ],
   "source": [
    "# work on testing data...\n",
    "classifier, training_time = br.trainData(\"MNB\", features_test, labels_test, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for the testing data is : \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99       728\n",
      "          1       1.00      0.99      0.99      1002\n",
      "\n",
      "avg / total       0.99      0.99      0.99      1730\n",
      "\n",
      "('Accuracy score for testing data is : ', 99.075144508670519)\n"
     ]
    }
   ],
   "source": [
    "# check for accuracy...\n",
    "labels_pred_test = br.predictResult(classifier, features_test)\n",
    "\n",
    "print(\"Classification report for the testing data is : \")\n",
    "print br.checkForAccuracy(labels_pred_test, labels_test)\n",
    "\n",
    "print(\"Accuracy score for testing data is : \", accuracy_score(labels_pred_test, labels_test)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Thats a pretty good and robust model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Review Status is : \n",
      "Negative\n"
     ]
    }
   ],
   "source": [
    "# validating on a new array...\n",
    "string = [\"Jupyter Ascending is a decent movie\"]\n",
    "\n",
    "movie_review_array = np.array(string)\n",
    "\n",
    "result = br.validateForNewVector(movie_review_array)\n",
    "\n",
    "print(\"The Review Status is : \")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
